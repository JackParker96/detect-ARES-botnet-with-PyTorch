{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10458b80-5032-44aa-8ed8-a3746e44ee4b",
   "metadata": {
    "id": "10458b80-5032-44aa-8ed8-a3746e44ee4b"
   },
   "source": [
    "# Jack Parker CYBERSEC520 Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DzimB08qWW8N",
   "metadata": {
    "id": "DzimB08qWW8N"
   },
   "source": [
    "### Sources\n",
    "\n",
    "[PyTorch Crash Course by AssemblyAI](https://www.youtube.com/watch?v=OIenNRt2bjg&t=2259s)\n",
    "\n",
    "CYBERSEC520 Class Notebook #4\n",
    "\n",
    "Official PyTorch documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e31020-50bd-40be-8ea6-64f306fd24a0",
   "metadata": {
    "id": "01e31020-50bd-40be-8ea6-64f306fd24a0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8708e93c-f530-499b-94a6-775cadc1bbd7",
   "metadata": {
    "id": "8708e93c-f530-499b-94a6-775cadc1bbd7"
   },
   "source": [
    "\n",
    "## Part 1: Hands-on with MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecc1599-1bb2-4743-bb7e-aa6d93b62a96",
   "metadata": {
    "id": "0ecc1599-1bb2-4743-bb7e-aa6d93b62a96"
   },
   "source": [
    "### Select a cybersecurity dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70cc012-b661-46c4-8315-0f55c59ab4a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "id": "f70cc012-b661-46c4-8315-0f55c59ab4a6",
    "outputId": "7518c982-41e0-4f59-d392-18b1faed3c1b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-54cdf852-defc-442d-a167-70e59ef228a3\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>...</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3268</td>\n",
       "      <td>112740690</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>6448</td>\n",
       "      <td>1152</td>\n",
       "      <td>403</td>\n",
       "      <td>0</td>\n",
       "      <td>201.5</td>\n",
       "      <td>204.724205</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>3.594286e+02</td>\n",
       "      <td>1.199802e+01</td>\n",
       "      <td>380</td>\n",
       "      <td>343</td>\n",
       "      <td>16100000.0</td>\n",
       "      <td>4.988048e+05</td>\n",
       "      <td>16400000</td>\n",
       "      <td>15400000</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>389</td>\n",
       "      <td>112740560</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>6448</td>\n",
       "      <td>5056</td>\n",
       "      <td>403</td>\n",
       "      <td>0</td>\n",
       "      <td>201.5</td>\n",
       "      <td>204.724205</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>3.202857e+02</td>\n",
       "      <td>1.574499e+01</td>\n",
       "      <td>330</td>\n",
       "      <td>285</td>\n",
       "      <td>16100000.0</td>\n",
       "      <td>4.987937e+05</td>\n",
       "      <td>16400000</td>\n",
       "      <td>15400000</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>113757377</td>\n",
       "      <td>545</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9.361829e+06</td>\n",
       "      <td>7.324646e+06</td>\n",
       "      <td>18900000</td>\n",
       "      <td>19</td>\n",
       "      <td>12200000.0</td>\n",
       "      <td>6.935824e+06</td>\n",
       "      <td>20800000</td>\n",
       "      <td>5504997</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5355</td>\n",
       "      <td>100126</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>616</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>54760</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 79 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54cdf852-defc-442d-a167-70e59ef228a3')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-54cdf852-defc-442d-a167-70e59ef228a3 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-54cdf852-defc-442d-a167-70e59ef228a3');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-2d13b59d-5a47-4713-832a-0c93878c4985\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2d13b59d-5a47-4713-832a-0c93878c4985')\"\n",
       "            title=\"Suggest charts.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-2d13b59d-5a47-4713-832a-0c93878c4985 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "    Destination Port   Flow Duration   Total Fwd Packets  \\\n",
       "0               3268       112740690                  32   \n",
       "1                389       112740560                  32   \n",
       "2                  0       113757377                 545   \n",
       "3               5355          100126                  22   \n",
       "4                  0           54760                   4   \n",
       "\n",
       "    Total Backward Packets  Total Length of Fwd Packets  \\\n",
       "0                       16                         6448   \n",
       "1                       16                         6448   \n",
       "2                        0                            0   \n",
       "3                        0                          616   \n",
       "4                        0                            0   \n",
       "\n",
       "    Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
       "0                          1152                     403   \n",
       "1                          5056                     403   \n",
       "2                             0                       0   \n",
       "3                             0                      28   \n",
       "4                             0                       0   \n",
       "\n",
       "    Fwd Packet Length Min   Fwd Packet Length Mean   Fwd Packet Length Std  \\\n",
       "0                       0                    201.5              204.724205   \n",
       "1                       0                    201.5              204.724205   \n",
       "2                       0                      0.0                0.000000   \n",
       "3                      28                     28.0                0.000000   \n",
       "4                       0                      0.0                0.000000   \n",
       "\n",
       "   ...   min_seg_size_forward   Active Mean    Active Std   Active Max  \\\n",
       "0  ...                     32  3.594286e+02  1.199802e+01          380   \n",
       "1  ...                     32  3.202857e+02  1.574499e+01          330   \n",
       "2  ...                      0  9.361829e+06  7.324646e+06     18900000   \n",
       "3  ...                     32  0.000000e+00  0.000000e+00            0   \n",
       "4  ...                      0  0.000000e+00  0.000000e+00            0   \n",
       "\n",
       "    Active Min   Idle Mean      Idle Std   Idle Max   Idle Min   Label  \n",
       "0          343  16100000.0  4.988048e+05   16400000   15400000  BENIGN  \n",
       "1          285  16100000.0  4.987937e+05   16400000   15400000  BENIGN  \n",
       "2           19  12200000.0  6.935824e+06   20800000    5504997  BENIGN  \n",
       "3            0         0.0  0.000000e+00          0          0  BENIGN  \n",
       "4            0         0.0  0.000000e+00          0          0  BENIGN  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"fri_morning.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622da8d-cd6f-4aef-aa7a-1cd55969fbeb",
   "metadata": {
    "id": "1622da8d-cd6f-4aef-aa7a-1cd55969fbeb"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c88175d-2d06-44ba-9af1-1d97ebc346dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1c88175d-2d06-44ba-9af1-1d97ebc346dc",
    "outputId": "9c23609a-42e5-48ed-deb8-331e611a5ef0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BENIGN    189067\n",
       "Bot         1966\n",
       "Name:  Label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dataset appears to be highly imbalanced\n",
    "# Therefore, accuracy is not a good measure of model performance\n",
    "# We will need to use metrics like ROC_AUC and F1-Score\n",
    "df[\" Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea56373-dde4-4376-ac34-7e98f7f0e967",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ea56373-dde4-4376-ac34-7e98f7f0e967",
    "outputId": "4190682d-ec72-4ef4-9eee-d2e557cca6fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for any infinite and null values\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9310d3e8-5224-4f22-8fc9-501454c6826b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9310d3e8-5224-4f22-8fc9-501454c6826b",
    "outputId": "760a460e-c853-404c-ffed-a0ed830a0a60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are very few rows with null values, so we can just drop those rows\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e22c92-b59d-417d-b876-35eda43e5276",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d3e22c92-b59d-417d-b876-35eda43e5276",
    "outputId": "f34ada65-2de7-46b4-ce9f-155dc10bdcef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    188955\n",
       "1      1956\n",
       "Name: bot, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign benign samples the label 0 and malicious samples the label 1\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df[\" Label\"])\n",
    "\n",
    "# Check to make sure that benign samples are assigned the label 0\n",
    "if le.classes_[0] != \"BENIGN\":\n",
    "    print(\"Labels are reversed: Fix before proceeding\")\n",
    "\n",
    "# Transform the labels\n",
    "encoded_labels = le.transform(df[\" Label\"])\n",
    "\n",
    "# Replace the old \"Label\" column with the encoded version\n",
    "df.drop(columns=[\" Label\"], inplace=True)\n",
    "df[\"bot\"] = encoded_labels\n",
    "\n",
    "# Check to make sure everything worked\n",
    "df[\"bot\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4cb447-d3dc-4b45-a5c7-1c8fc239d623",
   "metadata": {
    "id": "0b4cb447-d3dc-4b45-a5c7-1c8fc239d623"
   },
   "outputs": [],
   "source": [
    "# The only other encoding we need to do is for the \"Destination Port\" feature\n",
    "# We will frequency-encode this feature\n",
    "# Label encoding would introduce an artificial hierarchy that might harm model performance\n",
    "# One-hot encoding would introduce way too many more columns\n",
    "\n",
    "# Create a mapping from port number to frequency of occurrence of that port number in the dataset\n",
    "freq_mappings = df[\" Destination Port\"].value_counts().to_dict()\n",
    "\n",
    "# Create a new column that replaces each port number with the frequency of occurrence of that port number\n",
    "new_column = []\n",
    "for i in range(df.shape[0]):\n",
    "    port_num = df[\" Destination Port\"][i]\n",
    "    new_column.append(freq_mappings[port_num])\n",
    "\n",
    "# Replace old column with new column\n",
    "df[\" Destination Port\"] = new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UBPqUALwVH3n",
   "metadata": {
    "id": "UBPqUALwVH3n"
   },
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# We only want to normalize features, not labels\n",
    "# So drop the labels column\n",
    "# We will glue the labels back on to the dataframe once we've normalized all the features\n",
    "labels = df[\"bot\"]\n",
    "df.drop(columns=[\"bot\"], inplace=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df = pd.DataFrame(data=scaler.fit_transform(df),\n",
    "                  columns=df.columns)\n",
    "df[\"bot\"] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s8lShgedW1FF",
   "metadata": {
    "id": "s8lShgedW1FF"
   },
   "source": [
    "### Format the data for easy use with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i0zlc-cWXAIX",
   "metadata": {
    "id": "i0zlc-cWXAIX"
   },
   "outputs": [],
   "source": [
    "# Right now we're working with a Pandas dataframe\n",
    "# Although not essential, when using PyTorch to train neural networks it's nice to work with PyTorch Dataset objects\n",
    "# So we will define a custom Dataset class that we can use for our cybersecurity dataset\n",
    "\n",
    "# This class was generated using ChatGPT(3.5)\n",
    "class CyberDataset(Dataset): # Each custom dataset class inherits from the Dataset superclass\n",
    "  def __init__(self, dataframe):\n",
    "    self.data = dataframe\n",
    "\n",
    "  # Override the len() method to return the number of rows in the dataframe\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  # Override the getitem method to be able to easily refer to a row of the dataframe by number\n",
    "  def __getitem__(self, idx):\n",
    "    features = self.data.iloc[idx, :-1].values # Pull out the values of every feature for a single row\n",
    "    label = self.data.iloc[idx, -1] # Get the label for that particular row\n",
    "\n",
    "    # PyTorch likes to work with tensors, so we will change the features and labels to tensors\n",
    "    features = torch.tensor(features, dtype=torch.float32)\n",
    "    label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x5I5rMAta-Es",
   "metadata": {
    "id": "x5I5rMAta-Es"
   },
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features and labels\n",
    "X_df = df.iloc[:,:-1]\n",
    "y_df = df[[\"bot\"]]\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df,\n",
    "                                                    y_df,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Create train and test sets with both features and labels in a single dataframe\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "test_df = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# Construct CyberDataset objects from the two dataframes\n",
    "train_dataset = CyberDataset(train_df)\n",
    "test_dataset = CyberDataset(test_df)\n",
    "\n",
    "# PyTorch also provides \"DataLoaders\" which optimize performance when iterating over Datasets during training\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99e496c-ab3e-4118-8eaf-dce474af2786",
   "metadata": {
    "id": "f99e496c-ab3e-4118-8eaf-dce474af2786"
   },
   "source": [
    "### Train a deep learning model for classification on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51523438-d0b6-4c20-b09e-e77b30d905df",
   "metadata": {
    "id": "51523438-d0b6-4c20-b09e-e77b30d905df"
   },
   "outputs": [],
   "source": [
    "# If this notebook is running in an environment where a GPU is available, we want to make use of the GPU as much as possible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define hyperparameters\n",
    "input_size = X_train.shape[1] # Each sample in this dataset has 78 features, so X_train.shape[1] = 78\n",
    "hidden_size = 100 # Each hidden layer will have 100 neurons\n",
    "num_classes = 2 # There are only two types of labels, bot = 0 or bot = 1\n",
    "num_epochs = 3 # The model will see every training sample 3 times\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EtCdpefLGWcO",
   "metadata": {
    "id": "EtCdpefLGWcO"
   },
   "outputs": [],
   "source": [
    "# Define a class for our multi-layer perceptron\n",
    "class MLP(nn.Module): # In PyTorch, every neural network class we define should inherit from the nn.module superclass\n",
    "  def __init__(self, input_size, hidden_size, num_classes):\n",
    "    super(MLP, self).__init__() # We must call the constructor for the parent class\n",
    "    self.layer_1 = nn.Linear(input_size, hidden_size) # Fully connect the input layer and the hidden layer\n",
    "    self.relu = nn.ReLU() # Activation function that adds some non-linearity to the model\n",
    "    self.layer_2 = nn.Linear(hidden_size, num_classes) # Fully connect the hidden layer and the output layer\n",
    "\n",
    "  # Define a method to do a full forward pass of a single sample\n",
    "  def forward(self, x):\n",
    "    out = self.layer_1(x)\n",
    "    out = self.relu(out)\n",
    "    out = self.layer_2(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rCLwdivxJat5",
   "metadata": {
    "id": "rCLwdivxJat5"
   },
   "outputs": [],
   "source": [
    "# Create an MLP object for our cybersecurity dataset (and put the model on the GPU if one is available)\n",
    "model = MLP(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# Define a loss function (we will use cross entropy loss in this example)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# PyTorch provides \"optimizers\" that apply a layer of abstraction to the process of tuning the weights and biases of neural nets\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YSNrQjTnfP8X",
   "metadata": {
    "id": "YSNrQjTnfP8X"
   },
   "outputs": [],
   "source": [
    "# Define a function to train a neural network\n",
    "def train(num_epochs, train_loader, device, model, criterion, optimizer):\n",
    "  for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader): # Here's where the DataLoader comes in handy for optimizing iteration over training data\n",
    "      inputs = inputs.reshape(-1, input_size).to(device) # # Push the training samples to the device (hopefully a GPU)\n",
    "      labels = labels.to(device) # Push the lables to the device\n",
    "      outputs = model(inputs) # Forward pass of samples through the model\n",
    "      loss = criterion(outputs, labels) # Calculate loss\n",
    "      loss.backward() # Calculate gradient of loss with respect to model weights\n",
    "      optimizer.step() # Walk down the gradient a little bit\n",
    "      optimizer.zero_grad() # Reset the gradients (they will be calculated anew in the next iteration)\n",
    "\n",
    "# Train our MLP\n",
    "train(num_epochs,\n",
    "      train_loader,\n",
    "      device,\n",
    "      model,\n",
    "      criterion,\n",
    "      optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fe24e5-7b99-4ab8-b827-c7ddfd153158",
   "metadata": {
    "id": "34fe24e5-7b99-4ab8-b827-c7ddfd153158"
   },
   "source": [
    "### Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zFiSXrAVhpwO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zFiSXrAVhpwO",
    "outputId": "86be6e31-6d37-404f-ab87-76693daf7f06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.9947832333671316\n"
     ]
    }
   ],
   "source": [
    "# Define a function to calculate the F1-score of a trained model\n",
    "def test(test_loader, device, model):\n",
    "  # The following code was generated with ChatGPT(3.5)\n",
    "  # I had to tweak the code to get it to push inputs and labels to the device\n",
    "  true_labels = []\n",
    "  predicted_labels = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "      inputs = inputs.reshape(-1, input_size).to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      # Forward pass\n",
    "      outputs = model(inputs)\n",
    "\n",
    "      # Get predicted labels\n",
    "      _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "      # Convert to CPU if using GPU\n",
    "      predicted = predicted.cpu().numpy()\n",
    "      labels = labels.cpu().numpy()\n",
    "\n",
    "      true_labels.extend(labels)\n",
    "      predicted_labels.extend(predicted)\n",
    "\n",
    "  # Calculate the F1-score\n",
    "  f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "  return f1\n",
    "\n",
    "# Test our MLP\n",
    "result = test(test_loader,\n",
    "              device,\n",
    "              model)\n",
    "\n",
    "print(f\"F1-Score: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ad0079-706a-4ad8-b521-4d4a1b32c026",
   "metadata": {
    "id": "34ad0079-706a-4ad8-b521-4d4a1b32c026"
   },
   "source": [
    "### Tune model hyperparameters to improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WaeD8bzSi2zW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WaeD8bzSi2zW",
    "outputId": "2fb99a87-f1f9-422f-f948-5d952fa4b8e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-06; F1-Score: 0.9706801252470618\n",
      "Learning rate: 1e-05; F1-Score: 0.9836092053279863\n",
      "Learning rate: 0.0001; F1-Score: 0.9948154049518991\n",
      "Learning rate: 0.001; F1-Score: 0.9949336652342631\n",
      "Learning rate: 0.01; F1-Score: 0.9948579610096707\n",
      "Learning rate: 0.1; F1-Score: 0.9836092053279863\n",
      "Learning rate: 1; F1-Score: 0.9835699204678534\n"
     ]
    }
   ],
   "source": [
    "# We are already getting very strong performance with the first set of hyperparameters\n",
    "# The PyTorch Optomizer object takes care of tuning the model parameters (weights), but it doesn't adjust hyperparameters at all\n",
    "# Let's see if we can push performance even higher by tuning one of (if not the most) important hyperparameters: learning rate\n",
    "learning_rates = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1]\n",
    "\n",
    "for lr in learning_rates:\n",
    "  model = MLP(input_size, hidden_size, num_classes).to(device)\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "  train(num_epochs, train_loader, device, model, criterion, optimizer)\n",
    "  result = test(test_loader, device, model)\n",
    "  print(f\"Learning rate: {lr}; F1-Score: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YRrO91mboDIY",
   "metadata": {
    "id": "YRrO91mboDIY"
   },
   "source": [
    "#### It turns out that the learning rate we tried initially is the best out of the seven learning rates we tested."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
